{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Bio3d-vision example: _platelet-em_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the bio3d-vision project: [bio3d-vision.github.io](bio3d-vision.github.io)\n",
    "\n",
    "Authors: Matthew Guay (matthew.guay@nih.gov), Zeyad Emam (zeyad.emam@nih.gov)\n",
    "\n",
    "Last updated: September 10, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from bio3d_vision.augment import deform\n",
    "from bio3d_vision.preprocess import gen_conjugate_corners, \\\n",
    "    gen_corner_points, imshow, load, window_generator \n",
    "from bio3d_vision.rgb_to_index import platelet_em_rgb_map, rgb_to_index\n",
    "from bio3d_vision.download_and_extract import download_and_extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [bio3d-vision](https://bio3d-vision.github.io) dataset collection's goal is to aggregate high-quality, large-scale 3D biological microscopy datasets whose analyses present challenging computer vision problems of great importance to advancing the state of microscopy. \n",
    "\n",
    "The `bio3d_vision` package can be used to simplify the integration of bio3d-vision datasets into image processing and machine learning pipelines in Python. This notebook demonstrates how to use `bio3d_vision` to download the [platelet-em](https://bio3d-vision.github.io/platelet-description.html) dataset, load data into numpy, augment it, and window it to create collections of smaller regions for use with neural networks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Extract Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [platelet-em](https://bio3d-vision.github.io/platelet-description.html) dataset to a specified `download_dir`, if the dataset doesn't already exist there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download directory\n",
    "\n",
    "Change this to specify the directory where the dataset will be downloaded. The downloading script will create a new `platelet-em` directory within it if one does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to change download directory\n",
    "download_dir = '/home/matt/Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No platelet-em dataset found, downloading...\n",
      "Downloading https://www.dropbox.com/s/lo6i7v2mc9z2wft/images-and-labels.zip?dl=1 to /home/matt/Desktop/platelet-em/platelet-em.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 95600640/95753458 [00:31<00:00, 2887715.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/matt/Desktop/platelet-em/platelet-em.zip to /home/matt/Desktop/platelet-em\n"
     ]
    }
   ],
   "source": [
    "bio3d_url = \"https://www.dropbox.com/s/lo6i7v2mc9z2wft/images-and-labels.zip?dl=1\"\n",
    "bio3d_filename = \"platelet-em.zip\"\n",
    "bio3d_md5 = 'e3a7bb0b0099220781bfea3e5ee9430c'\n",
    "\n",
    "if not os.path.exists(os.path.join(download_dir, 'platelet-em')):\n",
    "    print('No platelet-em dataset found, downloading...')\n",
    "    download_and_extract(\n",
    "        bio3d_url, \n",
    "        download_dir, \n",
    "        filename=bio3d_filename,\n",
    "        md5=bio3d_md5)\n",
    "\n",
    "else:\n",
    "    print('Found `platelet-em` dataset already in ' + download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the 50x800x800 image and semantic label datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to image and semantic label data\n",
    "main_data_dir = os.path.join(download_dir, 'platelet-em')\n",
    "raw_data_dir = os.path.join(main_data_dir, 'images')\n",
    "raw_data_file = '50-images.tif'\n",
    "label_data_dir = os.path.join(main_data_dir, 'labels-semantic')\n",
    "label_data_file = '50-semantic.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load into numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "95756288it [00:50, 2887715.56it/s]                              "
     ]
    }
   ],
   "source": [
    "# Load raw and label data\n",
    "raw_data = load(raw_data_dir, raw_data_file)\n",
    "\n",
    "# Specify Data Type when loading label data\n",
    "label_data = load(label_data_dir, label_data_file, data_type=np.int32)\n",
    "\n",
    "# Label data is provided in RGB format (0-255). Convert to indices (0-7) as follows:\n",
    "# First get the mapping from RGB to index\n",
    "label_data = rgb_to_index(label_data, platelet_em_rgb_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample image (first image in each stack)\n",
    "images = OrderedDict()\n",
    "images[0] = raw_data[0]\n",
    "images[1] = label_data[0]\n",
    "\n",
    "plot_settings = OrderedDict()\n",
    "plot_settings[0] = {'cmap': 'gray'}\n",
    "plot_settings[1] = {'cmap':'jet', 'vmin':0, 'vmax':label_data.max()}\n",
    "\n",
    "imshow(images, (12, 6), plot_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation: Elastic Deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide code for elastic deformation. The user will likely want to add other common data augmentation and data normalization techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set deformation settings\n",
    "deformation_settings = dict()\n",
    "# TODO: Explain these\n",
    "deformation_settings['scale'] = 40\n",
    "deformation_settings['alpha'] = 20\n",
    "deformation_settings['sigma'] = 0.6\n",
    "\n",
    "# Choose deformation random seed (this is important to make sure both raw \n",
    "# and label data are deformed the same)\n",
    "deformation_random_seed = 1\n",
    "\n",
    "# Perform elastic deformation\n",
    "deformed_raw_data = deform(raw_data,\n",
    "                           random_seed=deformation_random_seed)\n",
    "\n",
    "deformed_label_data = deform(label_data,\n",
    "                             random_seed=deformation_random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show effect of deformations\n",
    "images = OrderedDict()\n",
    "images[0] = raw_data[0]\n",
    "images[1] = deformed_raw_data[0]\n",
    "\n",
    "plot_settings = OrderedDict()\n",
    "plot_settings[0] = {'cmap': 'gray'}\n",
    "plot_settings[1] = {'cmap':'gray'}\n",
    "\n",
    "imshow(images, (8, 4), plot_settings)\n",
    "\n",
    "images = OrderedDict()\n",
    "images[0] = label_data[0]\n",
    "images[1] = deformed_label_data[0]\n",
    "\n",
    "plot_settings = OrderedDict()\n",
    "plot_settings[0] = {'cmap':'jet', 'vmin':0, 'vmax':label_data.max()}\n",
    "plot_settings[1] = {'cmap':'jet', 'vmin':0, 'vmax':label_data.max()}\n",
    "\n",
    "imshow(images, (8, 4), plot_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We supply functionalities for random windowing as well as generating two windows of different shape centered at the same location (in case input and output of neural networks are different shapes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the windowing parameters\n",
    "random_windowing = True\n",
    "corner_generation_seed = 1\n",
    "label_window_shape = [5, 100, 200] # corresponds to the shape output by the neural network (smaller than input)\n",
    "window_spacing = [5, 50, 100] # implies there will be no overlap in z but half the image will overlap in x and y.\n",
    "corner_generation_random_seed = None\n",
    "\n",
    "# Generate a list of corner points for the labels\n",
    "label_corner_points = gen_corner_points(spatial_shape=deformed_label_data.shape,\n",
    "                                  window_spacing=window_spacing,\n",
    "                                  window_shape=label_window_shape,\n",
    "                                  random_windowing=random_windowing,\n",
    "                                  random_seed=corner_generation_random_seed)\n",
    "\n",
    "raw_window_shape = [5, 200, 400] # corresponds to the shape input to the neural network (larger than output)\n",
    "# We choose a much larger raw_window_shape to illustrate what's going on\n",
    "\n",
    "# Generate a list of corner poins for the raw inputs\n",
    "\n",
    "raw_corner_points = gen_conjugate_corners(corner_points=label_corner_points,\n",
    "                                          window_shape=label_window_shape,\n",
    "                                          conjugate_window_shape=raw_window_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform windowing\n",
    "raw_window_generator = window_generator(deformed_raw_data,\n",
    "                                        window_shape=raw_window_shape,\n",
    "                                        corner_points=raw_corner_points)\n",
    "label_window_generator = window_generator(deformed_label_data,\n",
    "                                          window_shape=label_window_shape,\n",
    "                                          corner_points=label_corner_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample windows (first image in each stack)\n",
    "# Notice the mirroring on the left in the raw window!\n",
    "images = OrderedDict()\n",
    "images[0] = next(raw_window_generator)[0]\n",
    "images[1] = next(label_window_generator)[0]\n",
    "\n",
    "plot_settings = OrderedDict()\n",
    "plot_settings[0] = {'cmap': 'gray'}\n",
    "plot_settings[1] = {'cmap':'jet', 'vmin':0, 'vmax':label_data.max()}\n",
    "\n",
    "imshow(images, (8, 4), plot_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also plot another set of windows here\n",
    "# Show sample windows (first image in each stack)\n",
    "# Notice the mirroring on the left in the raw window!\n",
    "images = OrderedDict()\n",
    "for _ in range(5):\n",
    "    images[0] = next(raw_window_generator)[0]\n",
    "    images[1] = next(label_window_generator)[0]\n",
    "\n",
    "plot_settings = OrderedDict()\n",
    "plot_settings[0] = {'cmap': 'gray'}\n",
    "plot_settings[1] = {'cmap':'jet', 'vmin':0, 'vmax':label_data.max()}\n",
    "\n",
    "imshow(images, (8, 4), plot_settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
